{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0693bd66",
   "metadata": {},
   "source": [
    "## 前處理統一版本 (from 彥文)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fa61c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\skych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\skych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\skych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\skych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\skych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger_eng.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\skych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 載入套件\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "import re\n",
    "import string\n",
    "import contractions\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "\n",
    "# 下載 NLTK 資源\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9e9ef12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "使用設備：cuda\n",
      "PyTorch 版本：2.5.1+cu121\n",
      "GPU 可用：True\n",
      "GPU 名稱：NVIDIA GeForce RTX 4060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "# 檢查 GPU 可用性並設置設備\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用設備：{device}\")\n",
    "print(f\"PyTorch 版本：{torch.__version__}\")\n",
    "print(f\"GPU 可用：{torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU 名稱：{torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87002c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化工具\n",
    "tokenizer = TweetTokenizer(preserve_case=False)\n",
    "encoder = LabelEncoder()\n",
    "custom_stopwords = set(stopwords.words('english')) - {\"not\", \"no\", \"never\"}\n",
    "\n",
    "# 定義資料清理函數（整合新程式碼，滿足原始要求）\n",
    "def clean_text(text, use_stopwords=False, replace_username=True, replace_covid='none'):\n",
    "    if pd.isna(text):\n",
    "        return []\n",
    "    \n",
    "    # 小寫\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 展開縮寫（新程式碼功能）\n",
    "    text = contractions.fix(text)\n",
    "    \n",
    "    # 移除網址\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text)\n",
    "    \n",
    "    # 處理 @人名（按原始要求替換為 username）\n",
    "    if replace_username:\n",
    "        text = re.sub(r\"@\\w+\", 'username', text)\n",
    "    \n",
    "    # 處理 covid/coronavirus（按原始要求替換為 virus）\n",
    "    if replace_covid == 'virus':\n",
    "        text = re.sub(r\"\\bcovid\\b|\\bcovid19\\b|\\bcoronavirus\\b\", 'virus', text, flags=re.IGNORECASE)\n",
    "    elif replace_covid == 'pandemic':\n",
    "        text = re.sub(r\"\\bcovid\\b|\\bcovid19\\b|\\bcoronavirus\\b\", 'pandemic', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # 保留字母（移除非字母字符）\n",
    "    text = re.sub(r\"[^a-zA-Z \\s]\", '', text)\n",
    "    \n",
    "    # 去除多餘空白\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    # 分詞（使用 word_tokenize，與新程式碼一致）\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # 移除停用詞（若啟用）\n",
    "    if use_stopwords:\n",
    "        tokens = [word for word in tokens if word not in custom_stopwords]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18a4c9fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練集資料筆數： 32925\n",
      "訓練集欄位： ['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'Sentiment']\n",
      "訓練集情緒分布：\n",
      " Positive              9137\n",
      "Negative              7934\n",
      "Neutral               6170\n",
      "Extremely Positive    5299\n",
      "Extremely Negative    4385\n",
      "Name: Sentiment, dtype: int64\n",
      "驗證集資料筆數： 8232\n",
      "驗證集欄位： ['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'Sentiment']\n",
      "驗證集情緒分布：\n",
      " Positive              2285\n",
      "Negative              1983\n",
      "Neutral               1543\n",
      "Extremely Positive    1325\n",
      "Extremely Negative    1096\n",
      "Name: Sentiment, dtype: int64\n",
      "測試集資料筆數： 3798\n",
      "測試集欄位： ['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'Sentiment']\n",
      "測試集情緒分布：\n",
      " Negative              1041\n",
      "Positive               947\n",
      "Neutral                619\n",
      "Extremely Positive     599\n",
      "Extremely Negative     592\n",
      "Name: Sentiment, dtype: int64\n",
      "警告：訓練集有 10 筆空序列，移除中...\n",
      "空序列範例：\n",
      "                                           OriginalTweet clean_tokens\n",
      "29888  ???? ????? \\r\\r\\n????? ??? ? ?? ?? ??\\r\\r\\n\\r\\...           []\n",
      "27932  ?????: ???? ?????? ? ????????\\r\\r\\n.\\r\\r\\n?? ?...           []\n",
      "13843  ? ???? ????? ???? ??? ?????? ??? ???\\r\\r\\n\\r\\r...           []\n",
      "583    #????_???_?????? ???? ???????..? ?? ?????? ?? ...           []\n",
      "16920  ???? ??????? ??????? ???? ????? ???? ???? ????...           []\n",
      "警告：驗證集有 4 筆空序列，移除中...\n",
      "空序列範例：\n",
      "                                           OriginalTweet clean_tokens\n",
      "16     ????? ????? ????? ????? ??\\r\\r\\n?????? ????? ?...           []\n",
      "16924  ????? ?\\r\\r\\n\\r\\r\\n???? ??? ???? ??? ?????????...           []\n",
      "2385   ?? ??? ???. ????????-????? ?????? 3 ??????????...           []\n",
      "36781  ??? ???? ????? ?? ?????? ???? ????? ? ???? ???...           []\n",
      "\n",
      "訓練集處理結果：\n",
      "                                           OriginalTweet  \\\n",
      "3730   @Eater To everyone hoarding rice who until now...   \n",
      "35121  If your going to eat @ChickfilA they have comp...   \n",
      "9893   Watch this if you are one of those idiots who ...   \n",
      "34429  We need to have a risk management system more ...   \n",
      "29290  Markets plunge puts pension freedoms to the te...   \n",
      "\n",
      "                                            clean_tokens           Sentiment  \\\n",
      "3730   [username, to, everyone, hoarding, rice, who, ...  Extremely Negative   \n",
      "35121  [if, your, going, to, eat, username, they, hav...  Extremely Positive   \n",
      "9893   [watch, this, if, you, are, one, of, those, id...  Extremely Negative   \n",
      "34429  [we, need, to, have, a, risk, management, syst...            Positive   \n",
      "29290  [markets, plunge, puts, pension, freedoms, to,...            Positive   \n",
      "\n",
      "       SentimentEncoded  \n",
      "3730                  0  \n",
      "35121                 1  \n",
      "9893                  0  \n",
      "34429                 4  \n",
      "29290                 4  \n",
      "\n",
      "驗證集處理結果：\n",
      "                                           OriginalTweet  \\\n",
      "29012  Meanwhile a villager of quenching her thirsty ...   \n",
      "31777  U.S. Ethanol and Biodiesel Trends in Prices an...   \n",
      "20592  #WritingCommunity Today, my husband came home ...   \n",
      "36878  So there's no cure for a virus (#coronavirus) ...   \n",
      "34648  Like the good New Yorker I am, I talked myself...   \n",
      "\n",
      "                                            clean_tokens           Sentiment  \\\n",
      "29012  [meanwhile, a, villager, of, quenching, her, t...             Neutral   \n",
      "31777  [yous, ethanol, and, biodiesel, trends, in, pr...            Positive   \n",
      "20592  [writingcommunity, today, my, husband, came, h...  Extremely Positive   \n",
      "36878  [so, there, is, no, cure, for, a, virus, coron...  Extremely Negative   \n",
      "34648  [like, the, good, new, yorker, i, am, i, talke...  Extremely Positive   \n",
      "\n",
      "       SentimentEncoded  \n",
      "29012                 3  \n",
      "31777                 4  \n",
      "20592                 1  \n",
      "36878                 0  \n",
      "34648                 1  \n",
      "\n",
      "測試集處理結果：\n",
      "                                       OriginalTweet  \\\n",
      "0  TRENDING: New Yorkers encounter empty supermar...   \n",
      "1  When I couldn't find hand sanitizer at Fred Me...   \n",
      "2  Find out how you can protect yourself and love...   \n",
      "3  #Panic buying hits #NewYork City as anxious sh...   \n",
      "4  #toiletpaper #dunnypaper #coronavirus #coronav...   \n",
      "\n",
      "                                        clean_tokens           Sentiment  \\\n",
      "0  [trending, new, yorkers, encounter, empty, sup...  Extremely Negative   \n",
      "1  [when, i, could, not, find, hand, sanitizer, a...            Positive   \n",
      "2  [find, out, how, you, can, protect, yourself, ...  Extremely Positive   \n",
      "3  [panic, buying, hits, newyork, city, as, anxio...            Negative   \n",
      "4  [toiletpaper, dunnypaper, coronavirus, coronav...             Neutral   \n",
      "\n",
      "   SentimentEncoded  \n",
      "0                 0  \n",
      "1                 4  \n",
      "2                 1  \n",
      "3                 2  \n",
      "4                 3  \n"
     ]
    }
   ],
   "source": [
    "# 讀取資料\n",
    "df_train = pd.read_csv('Corona_NLP_train.csv', encoding='latin_1')\n",
    "df_test = pd.read_csv('Corona_NLP_test.csv', encoding='latin_1')\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.2, stratify=df_train[\"Sentiment\"], random_state=42)\n",
    "\n",
    "# 顯示資料統計\n",
    "print(\"訓練集資料筆數：\", len(df_train))\n",
    "print(\"訓練集欄位：\", df_train.columns.tolist())\n",
    "print(\"訓練集情緒分布：\\n\", df_train[\"Sentiment\"].value_counts())\n",
    "print(\"驗證集資料筆數：\", len(df_val))\n",
    "print(\"驗證集欄位：\", df_val.columns.tolist())\n",
    "print(\"驗證集情緒分布：\\n\", df_val[\"Sentiment\"].value_counts())\n",
    "print(\"測試集資料筆數：\", len(df_test))\n",
    "print(\"測試集欄位：\", df_test.columns.tolist())\n",
    "print(\"測試集情緒分布：\\n\", df_test[\"Sentiment\"].value_counts())\n",
    "\n",
    "# 套用前處理函數（初始清理，無停用詞）\n",
    "df_train[\"clean_tokens\"] = df_train[\"OriginalTweet\"].apply(lambda x: clean_text(x, use_stopwords=False))\n",
    "df_val[\"clean_tokens\"] = df_val[\"OriginalTweet\"].apply(lambda x: clean_text(x, use_stopwords=False))\n",
    "df_test[\"clean_tokens\"] = df_test[\"OriginalTweet\"].apply(lambda x: clean_text(x, use_stopwords=False))\n",
    "\n",
    "# 檢查空序列並移除\n",
    "empty_train = df_train[df_train['clean_tokens'].apply(len) == 0]\n",
    "if not empty_train.empty:\n",
    "    print(f\"警告：訓練集有 {len(empty_train)} 筆空序列，移除中...\")\n",
    "    print(\"空序列範例：\")\n",
    "    print(empty_train[['OriginalTweet', 'clean_tokens']].head())\n",
    "    df_train = df_train[df_train['clean_tokens'].apply(len) > 0]\n",
    "\n",
    "empty_val = df_val[df_val['clean_tokens'].apply(len) == 0]\n",
    "if not empty_val.empty:\n",
    "    print(f\"警告：驗證集有 {len(empty_val)} 筆空序列，移除中...\")\n",
    "    print(\"空序列範例：\")\n",
    "    print(empty_val[['OriginalTweet', 'clean_tokens']].head())\n",
    "    df_val = df_val[df_val['clean_tokens'].apply(len) > 0]\n",
    "\n",
    "empty_test = df_test[df_test['clean_tokens'].apply(len) == 0]\n",
    "if not empty_test.empty:\n",
    "    print(f\"警告：測試集有 {len(empty_test)} 筆空序列，移除中...\")\n",
    "    print(\"空序列範例：\")\n",
    "    print(empty_test[['OriginalTweet', 'clean_tokens']].head())\n",
    "    df_test = df_test[df_test['clean_tokens'].apply(len) > 0]\n",
    "\n",
    "# 處理情緒標籤\n",
    "df_train[\"SentimentEncoded\"] = encoder.fit_transform(df_train[\"Sentiment\"])\n",
    "df_val[\"SentimentEncoded\"] = encoder.transform(df_val[\"Sentiment\"])\n",
    "df_test[\"SentimentEncoded\"] = encoder.transform(df_test[\"Sentiment\"])\n",
    "\n",
    "# 顯示處理結果\n",
    "print(\"\\n訓練集處理結果：\")\n",
    "print(df_train[[\"OriginalTweet\", \"clean_tokens\", \"Sentiment\", \"SentimentEncoded\"]].head())\n",
    "print(\"\\n驗證集處理結果：\")\n",
    "print(df_val[[\"OriginalTweet\", \"clean_tokens\", \"Sentiment\", \"SentimentEncoded\"]].head())\n",
    "print(\"\\n測試集處理結果：\")\n",
    "print(df_test[[\"OriginalTweet\", \"clean_tokens\", \"Sentiment\", \"SentimentEncoded\"]].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
