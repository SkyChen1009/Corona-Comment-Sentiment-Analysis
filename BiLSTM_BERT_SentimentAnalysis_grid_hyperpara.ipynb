{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0cf3427",
   "metadata": {},
   "source": [
    "# Using BERT + BiLSTM as Sentiment Analyzer\n",
    "## Unified preprocessed:\n",
    "1. 字母小寫\n",
    "2. 刪除網址\n",
    "3. 移除標點符號（所有標點符號都要刪除）\n",
    "4. 移除非英文字母\n",
    "5. 計算類別權重（class_weight）\n",
    "6. 移除停用詞（stop_words）\n",
    "7. 不替換用戶名（replace_username：False）\n",
    "8. 不替換 COVID 相關詞彙（replace_covid：False）\n",
    "\n",
    "### 2025/05/29 01:49 by sky\n",
    "## gradient search for following hyperparameter：\n",
    "### 階段一\n",
    "    batch sizes = [64, 128, 256]\n",
    "    學習率=[0.01,0.001, 0.0001]\n",
    "### 階段二\n",
    "    hidden_dim=[128, 256, 512]\n",
    "    num_layers=[2, 3, 4]\n",
    "    dropout=[0.1, 0.2, 0.3]\n",
    "### 階段三\n",
    "    max lengths = [30, 50]\n",
    "### 階段四\n",
    "    pooling methods = ['hidden state', 'max pooling', 'mean pooling']\n",
    "    activation function：[None, ReLU, tanh]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae9737e",
   "metadata": {},
   "source": [
    "## 步驟1：載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaf28f74-fe20-4d48-bbec-2794f7c59673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a89157e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import re\n",
    "import string\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import matplotlib.font_manager as fm\n",
    "from itertools import product\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a5c6174",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\skych\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 設置中文字型\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft JhengHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c48c1ed",
   "metadata": {},
   "source": [
    "# 步驟2：設置參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4fe834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 5  # 五種情感類別\n",
    "EPOCHS = 15  # 訓練輪數\n",
    "PATIENCE = 5  # 早停耐心值\n",
    "CLIP_GRAD_NORM = 1.0  # 梯度裁剪範圍\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55ba7bf5-650e-40f8-8c67-00d966697c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_params = {\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 0.0001,\n",
    "    'hidden_dim': 256,\n",
    "    'num_layers': 4,\n",
    "    'dropout': 0.2,\n",
    "    'max_length': 50,\n",
    "    'pooling_method': 'max pooling',  # 修正為 'max pooling'\n",
    "    'activation_function': 'softmax'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5a620c8-9c38-410c-b42d-154825c547e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 階段性參數\n",
    "stage_params = {\n",
    "    'stage1': {\n",
    "        'batch_size': [64, 128, 256],\n",
    "        'learning_rate': [0.01, 0.001, 0.0001]\n",
    "    },\n",
    "    'stage2': {\n",
    "        'hidden_dim': [128, 256, 512],\n",
    "        'num_layers': [2, 3, 4],\n",
    "        'dropout': [0.1, 0.2, 0.3]\n",
    "    },\n",
    "    'stage3': {\n",
    "        'max_length': [30, 50]\n",
    "    },\n",
    "    'stage4': {\n",
    "        'pooling_method': ['hidden state', 'max pooling', 'mean pooling'],\n",
    "        'activation_function': [None, 'ReLU', 'tanh', 'softmax']\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd78d70",
   "metadata": {},
   "source": [
    "## 步驟3：資料清理函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5cfc3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 步驟3：資料清理函數\n",
    "def clean_text(text):\n",
    "    # 轉換為小寫\n",
    "    text = text.lower()\n",
    "    # 移除網址\n",
    "    text = re.sub(r'http\\\\S+|www\\\\S+|https\\\\S+', '', text, flags=re.MULTILINE)\n",
    "    # 移除標點符號\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # 移除非英文字母\n",
    "    text = re.sub(r'[^a-z\\\\s]', '', text)\n",
    "    # 自定義停用詞（保留情感相關詞彙）\n",
    "    custom_stop_words = set(stopwords.words('english')) - {'not', 'very', 'really'}\n",
    "    text = ' '.join(word for word in text.split() if word not in custom_stop_words)\n",
    "    # 移除多餘空格\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424aa051",
   "metadata": {},
   "source": [
    "## 步驟4：讀取資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a103c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均長度: 1.00, 最大長度: 1\n",
      "清理後的訓練資料前5筆：\n",
      "                                       OriginalTweet  \\\n",
      "0  @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...   \n",
      "1  advice Talk to your neighbours family to excha...   \n",
      "2  Coronavirus Australia: Woolworths to give elde...   \n",
      "3  My food stock is not the only one which is emp...   \n",
      "4  Me, ready to go at supermarket during the #COV...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  menyrbiephilgahanchrisitvhttpstcoifzfanpaandht...  \n",
      "1  advicetalktoyourneighboursfamilytoexchangephon...  \n",
      "2  coronavirusaustraliawoolworthstogiveelderlydis...  \n",
      "3  myfoodstockisnottheonlyonewhichisemptypleasedo...  \n",
      "4  mereadytogoatsupermarketduringthecovidoutbreak...  \n",
      "\n",
      "清理後的測試資料前5筆：\n",
      "                                       OriginalTweet  \\\n",
      "0  TRENDING: New Yorkers encounter empty supermar...   \n",
      "1  When I couldn't find hand sanitizer at Fred Me...   \n",
      "2  Find out how you can protect yourself and love...   \n",
      "3  #Panic buying hits #NewYork City as anxious sh...   \n",
      "4  #toiletpaper #dunnypaper #coronavirus #coronav...   \n",
      "\n",
      "                                          clean_text  \n",
      "0  trendingnewyorkersencounteremptysupermarketshe...  \n",
      "1  whenicouldntfindhandsanitizeratfredmeyeriturne...  \n",
      "2  findouthowyoucanprotectyourselfandlovedonesfro...  \n",
      "3  panicbuyinghitsnewyorkcityasanxiousshopperssto...  \n",
      "4  toiletpaperdunnypapercoronaviruscoronavirusaus...  \n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('Corona_NLP_train.csv', encoding='latin1')\n",
    "test_df = pd.read_csv('Corona_NLP_test.csv', encoding='latin1')\n",
    "\n",
    "# 清理資料\n",
    "train_df['clean_text'] = train_df['OriginalTweet'].apply(clean_text)\n",
    "test_df['clean_text'] = test_df['OriginalTweet'].apply(clean_text)\n",
    "\n",
    "# 檢查清理後文本長度\n",
    "text_lengths = train_df['clean_text'].apply(lambda x: len(x.split()))\n",
    "print(f\"平均長度: {text_lengths.mean():.2f}, 最大長度: {text_lengths.max()}\")\n",
    "\n",
    "print(\"清理後的訓練資料前5筆：\")\n",
    "print(train_df[['OriginalTweet', 'clean_text']].head())\n",
    "print(\"\\n清理後的測試資料前5筆：\")\n",
    "print(test_df[['OriginalTweet', 'clean_text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a06ff29",
   "metadata": {},
   "source": [
    "## 步驟5：標籤編碼 & class weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84056b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "訓練資料類別分佈：\n",
      "label\n",
      "3    11422\n",
      "1     9917\n",
      "2     7713\n",
      "4     6624\n",
      "0     5481\n",
      "Name: count, dtype: int64\n",
      "\n",
      "測試資料類別分佈：\n",
      "label\n",
      "1    1041\n",
      "3     947\n",
      "2     619\n",
      "4     599\n",
      "0     592\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_mapping = {\n",
    "    'Extremely Negative': 0,\n",
    "    'Negative': 1,\n",
    "    'Neutral': 2,\n",
    "    'Positive': 3,\n",
    "    'Extremely Positive': 4\n",
    "}\n",
    "train_df['label'] = train_df['Sentiment'].map(sentiment_mapping)\n",
    "test_df['label'] = test_df['Sentiment'].map(sentiment_mapping)\n",
    "\n",
    "print(\"\\n訓練資料類別分佈：\")\n",
    "print(train_df['label'].value_counts())\n",
    "print(\"\\n測試資料類別分佈：\")\n",
    "print(test_df['label'].value_counts())\n",
    "\n",
    "# 計算類別權重\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(train_df['label']), y=train_df['label'])\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1f1de",
   "metadata": {},
   "source": [
    "## 步驟 6：創建自定義資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a365d530",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70110f14",
   "metadata": {},
   "source": [
    "## 步驟7：定義 BERT-BiLSTM 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "107ce86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertBiLSTM(nn.Module):\n",
    "    def __init__(self, hidden_dim, output_dim, num_layers, dropout, pooling_method, activation_function):\n",
    "        super(BertBiLSTM, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        for param in self.bert.encoder.layer[:10].parameters():\n",
    "            param.requires_grad = False\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=768,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            bidirectional=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.pooling_method = pooling_method\n",
    "        if pooling_method == 'hidden state':\n",
    "            self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        else:\n",
    "            self.fc = nn.Linear(hidden_dim * 4, output_dim)\n",
    "        self.activation_function = activation_function\n",
    "        if activation_function == 'ReLU':\n",
    "            self.activation = nn.ReLU()\n",
    "        elif activation_function == 'tanh':\n",
    "            self.activation = nn.Tanh()\n",
    "        elif activation_function == 'softmax':\n",
    "            self.activation = nn.Softmax(dim=1)\n",
    "        else:\n",
    "            self.activation = None\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        bert_outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        embedded = bert_outputs[0]\n",
    "        lstm_out, (hidden, _) = self.lstm(embedded)\n",
    "        if self.pooling_method == 'hidden state':\n",
    "            hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "            pooled = hidden\n",
    "        elif self.pooling_method == 'max pooling':\n",
    "            max_pool, _ = torch.max(lstm_out, dim=1)\n",
    "            avg_pool = torch.mean(lstm_out, dim=1)\n",
    "            pooled = torch.cat((max_pool, avg_pool), dim=1)\n",
    "        elif self.pooling_method == 'mean pooling':\n",
    "            pooled = torch.mean(lstm_out, dim=1)\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid pooling_method: {self.pooling_method}. Expected 'hidden state', 'max pooling', or 'mean pooling'.\")\n",
    "        pooled = self.dropout(pooled)\n",
    "        output = self.fc(pooled)\n",
    "        if self.activation:\n",
    "            output = self.activation(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6145d910",
   "metadata": {},
   "source": [
    "## 步驟8：訓練與驗證函數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "934829bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in tqdm(data_loader, desc=\"訓練\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), CLIP_GRAD_NORM)\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    return total_loss / len(data_loader), correct / total\n",
    "\n",
    "def evaluate(model, data_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc=\"驗證\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    return total_loss / len(data_loader), correct / total, f1, all_preds, all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44b668e",
   "metadata": {},
   "source": [
    "## 步驟 9：階段性參數實驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8f7130f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def staged_search():\n",
    "    best_params = default_params.copy()\n",
    "    best_val_acc = 0\n",
    "    results = []\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    # 階段一：batch_size 和 learning_rate\n",
    "    print(\"\\n階段一：測試 batch_size 和 learning_rate\")\n",
    "    for batch_size, learning_rate in product(stage_params['stage1']['batch_size'], stage_params['stage1']['learning_rate']):\n",
    "        print(f\"\\n測試參數：batch_size={batch_size}, learning_rate={learning_rate}\")\n",
    "        train_dataset = TweetDataset(\n",
    "            texts=train_df['clean_text'].to_numpy(),\n",
    "            labels=train_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=best_params['max_length']\n",
    "        )\n",
    "        test_dataset = TweetDataset(\n",
    "            texts=test_df['clean_text'].to_numpy(),\n",
    "            labels=test_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=best_params['max_length']\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "        model = BertBiLSTM(\n",
    "            hidden_dim=best_params['hidden_dim'],\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            num_layers=best_params['num_layers'],\n",
    "            dropout=best_params['dropout'],\n",
    "            pooling_method=best_params['pooling_method'],\n",
    "            activation_function=best_params['activation_function']\n",
    "        ).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': model.bert.parameters(), 'lr': learning_rate, 'weight_decay': 1e-4},\n",
    "            {'params': list(model.lstm.parameters()) + list(model.fc.parameters()), 'lr': learning_rate, 'weight_decay': 1e-4}\n",
    "        ])\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "        best_val_loss = float('inf')\n",
    "        counter = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_acc, val_f1, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "            scheduler.step()\n",
    "            print(f'輪次 {epoch+1}/{EPOCHS}, 訓練損失: {train_loss:.4f}, 訓練準確率: {train_acc:.4f}')\n",
    "            print(f'驗證損失: {val_loss:.4f}, 驗證準確率: {val_acc:.4f}, F1: {val_f1:.4f}')\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= PATIENCE:\n",
    "                    print(f'早停於輪次 {epoch+1}')\n",
    "                    break\n",
    "        results.append({\n",
    "            'stage': 1,\n",
    "            'batch_size': batch_size,\n",
    "            'learning_rate': learning_rate,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1\n",
    "        })\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params['batch_size'] = batch_size\n",
    "            best_params['learning_rate'] = learning_rate\n",
    "    print(f\"\\n階段一最佳參數：batch_size={best_params['batch_size']}, learning_rate={best_params['learning_rate']}, 驗證準確率={best_val_acc:.4f}\")\n",
    "\n",
    "    # 階段二：hidden_dim, num_layers, dropout\n",
    "    print(\"\\n階段二：測試 hidden_dim, num_layers, dropout\")\n",
    "    for hidden_dim, num_layers, dropout in product(stage_params['stage2']['hidden_dim'], stage_params['stage2']['num_layers'], stage_params['stage2']['dropout']):\n",
    "        print(f\"\\n測試參數：hidden_dim={hidden_dim}, num_layers={num_layers}, dropout={dropout}\")\n",
    "        train_dataset = TweetDataset(\n",
    "            texts=train_df['clean_text'].to_numpy(),\n",
    "            labels=train_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=best_params['max_length']\n",
    "        )\n",
    "        test_dataset = TweetDataset(\n",
    "            texts=test_df['clean_text'].to_numpy(),\n",
    "            labels=test_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=best_params['max_length']\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'])\n",
    "        model = BertBiLSTM(\n",
    "            hidden_dim=hidden_dim,\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout,\n",
    "            pooling_method=best_params['pooling_method'],\n",
    "            activation_function=best_params['activation_function']\n",
    "        ).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': model.bert.parameters(), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4},\n",
    "            {'params': list(model.lstm.parameters()) + list(model.fc.parameters()), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4}\n",
    "        ])\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "        best_val_loss = float('inf')\n",
    "        counter = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_acc, val_f1, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "            scheduler.step()\n",
    "            print(f'輪次 {epoch+1}/{EPOCHS}, 訓練損失: {train_loss:.4f}, 訓練準確率: {train_acc:.4f}')\n",
    "            print(f'驗證損失: {val_loss:.4f}, 驗證準確率: {val_acc:.4f}, F1: {val_f1:.4f}')\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= PATIENCE:\n",
    "                    print(f'早停於輪次 {epoch+1}')\n",
    "                    break\n",
    "        results.append({\n",
    "            'stage': 2,\n",
    "            'hidden_dim': hidden_dim,\n",
    "            'num_layers': num_layers,\n",
    "            'dropout': dropout,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1\n",
    "        })\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params['hidden_dim'] = hidden_dim\n",
    "            best_params['num_layers'] = num_layers\n",
    "            best_params['dropout'] = dropout\n",
    "    print(f\"\\n階段二最佳參數：hidden_dim={best_params['hidden_dim']}, num_layers={best_params['num_layers']}, dropout={best_params['dropout']}, 驗證準確率={best_val_acc:.4f}\")\n",
    "\n",
    "    # 階段三：max_length\n",
    "    print(\"\\n階段三：測試 max_length\")\n",
    "    for max_length in stage_params['stage3']['max_length']:\n",
    "        print(f\"\\n測試參數：max_length={max_length}\")\n",
    "        train_dataset = TweetDataset(\n",
    "            texts=train_df['clean_text'].to_numpy(),\n",
    "            labels=train_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=max_length\n",
    "        )\n",
    "        test_dataset = TweetDataset(\n",
    "            texts=test_df['clean_text'].to_numpy(),\n",
    "            labels=test_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=max_length\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'])\n",
    "        model = BertBiLSTM(\n",
    "            hidden_dim=best_params['hidden_dim'],\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            num_layers=best_params['num_layers'],\n",
    "            dropout=best_params['dropout'],\n",
    "            pooling_method=best_params['pooling_method'],\n",
    "            activation_function=best_params['activation_function']\n",
    "        ).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': model.bert.parameters(), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4},\n",
    "            {'params': list(model.lstm.parameters()) + list(model.fc.parameters()), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4}\n",
    "        ])\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "        best_val_loss = float('inf')\n",
    "        counter = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_acc, val_f1, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "            scheduler.step()\n",
    "            print(f'輪次 {epoch+1}/{EPOCHS}, 訓練損失: {train_loss:.4f}, 訓練準確率: {train_acc:.4f}')\n",
    "            print(f'驗證損失: {val_loss:.4f}, 驗證準確率: {val_acc:.4f}, F1: {val_f1:.4f}')\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= PATIENCE:\n",
    "                    print(f'早停於輪次 {epoch+1}')\n",
    "                    break\n",
    "        results.append({\n",
    "            'stage': 3,\n",
    "            'max_length': max_length,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1\n",
    "        })\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params['max_length'] = max_length\n",
    "    print(f\"\\n階段三最佳參數：max_length={best_params['max_length']}, 驗證準確率={best_val_acc:.4f}\")\n",
    "\n",
    "    # 階段四：pooling_method 和 activation_function\n",
    "    print(\"\\n階段四：測試 pooling_method 和 activation_function\")\n",
    "    for pooling_method, activation_function in product(stage_params['stage4']['pooling_method'], stage_params['stage4']['activation_function']):\n",
    "        print(f\"\\n測試參數：pooling_method={pooling_method}, activation_function={activation_function}\")\n",
    "        train_dataset = TweetDataset(\n",
    "            texts=train_df['clean_text'].to_numpy(),\n",
    "            labels=train_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=best_params['max_length']\n",
    "        )\n",
    "        test_dataset = TweetDataset(\n",
    "            texts=test_df['clean_text'].to_numpy(),\n",
    "            labels=test_df['label'].to_numpy(),\n",
    "            tokenizer=tokenizer,\n",
    "            max_len=best_params['max_length']\n",
    "        )\n",
    "        train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'])\n",
    "        model = BertBiLSTM(\n",
    "            hidden_dim=best_params['hidden_dim'],\n",
    "            output_dim=OUTPUT_DIM,\n",
    "            num_layers=best_params['num_layers'],\n",
    "            dropout=best_params['dropout'],\n",
    "            pooling_method=pooling_method,\n",
    "            activation_function=activation_function\n",
    "        ).to(device)\n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': model.bert.parameters(), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4},\n",
    "            {'params': list(model.lstm.parameters()) + list(model.fc.parameters()), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4}\n",
    "        ])\n",
    "        scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "        best_val_loss = float('inf')\n",
    "        counter = 0\n",
    "        for epoch in range(EPOCHS):\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "            val_loss, val_acc, val_f1, _, _ = evaluate(model, test_loader, criterion, device)\n",
    "            scheduler.step()\n",
    "            print(f'輪次 {epoch+1}/{EPOCHS}, 訓練損失: {train_loss:.4f}, 訓練準確率: {train_acc:.4f}')\n",
    "            print(f'驗證損失: {val_loss:.4f}, 驗證準確率: {val_acc:.4f}, F1: {val_f1:.4f}')\n",
    "            if val_loss < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "                if counter >= PATIENCE:\n",
    "                    print(f'早停於輪次 {epoch+1}')\n",
    "                    break\n",
    "        results.append({\n",
    "            'stage': 4,\n",
    "            'pooling_method': pooling_method,\n",
    "            'activation_function': activation_function,\n",
    "            'val_acc': val_acc,\n",
    "            'val_f1': val_f1\n",
    "        })\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params['pooling_method'] = pooling_method\n",
    "            best_params['activation_function'] = activation_function\n",
    "    print(f\"\\n階段四最佳參數：pooling_method={best_params['pooling_method']}, activation_function={best_params['activation_function']}, 驗證準確率={best_val_acc:.4f}\")\n",
    "\n",
    "    # 儲存結果\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_csv('staged_search_results.csv', index=False)\n",
    "    print(f\"\\n最終最佳參數：{best_params}\")\n",
    "    print(f\"最終最佳驗證準確率: {best_val_acc:.4f}\")\n",
    "\n",
    "    # 使用最佳參數進行最終訓練並生成混淆矩陣\n",
    "    print(\"\\n使用最佳參數進行最終訓練...\")\n",
    "    train_dataset = TweetDataset(\n",
    "        texts=train_df['clean_text'].to_numpy(),\n",
    "        labels=train_df['label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=best_params['max_length']\n",
    "    )\n",
    "    test_dataset = TweetDataset(\n",
    "        texts=test_df['clean_text'].to_numpy(),\n",
    "        labels=test_df['label'].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        max_len=best_params['max_length']\n",
    "    )\n",
    "    train_loader = DataLoader(train_dataset, batch_size=best_params['batch_size'], shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=best_params['batch_size'])\n",
    "    model = BertBiLSTM(\n",
    "        hidden_dim=best_params['hidden_dim'],\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        num_layers=best_params['num_layers'],\n",
    "        dropout=best_params['dropout'],\n",
    "        pooling_method=best_params['pooling_method'],\n",
    "        activation_function=best_params['activation_function']\n",
    "    ).to(device)\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights).to(device)\n",
    "    optimizer = optim.Adam([\n",
    "        {'params': model.bert.parameters(), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4},\n",
    "        {'params': list(model.lstm.parameters()) + list(model.fc.parameters()), 'lr': best_params['learning_rate'], 'weight_decay': 1e-4}\n",
    "    ])\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accuracies = []\n",
    "    best_val_loss = float('inf')\n",
    "    counter = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        val_loss, val_acc, val_f1, all_preds, all_labels = evaluate(model, test_loader, criterion, device)\n",
    "        scheduler.step()\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        val_accuracies.append(val_acc)\n",
    "        print(f'輪次 {epoch+1}/{EPOCHS}')\n",
    "        print(f'訓練損失: {train_loss:.4f}, 訓練準確率: {train_acc:.4f}')\n",
    "        print(f'驗證損失: {val_loss:.4f}, 驗證準確率: {val_acc:.4f}, F1: {val_f1:.4f}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_model_state = copy.deepcopy(model.state_dict())\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= PATIENCE:\n",
    "                print(f'早停於輪次 {epoch+1}')\n",
    "                break\n",
    "\n",
    "    # 載入最佳模型\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # 生成混淆矩陣\n",
    "    sentiment_labels = ['Extremely Negative', 'Negative', 'Neutral', 'Positive', 'Extremely Positive']\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=sentiment_labels, yticklabels=sentiment_labels)\n",
    "    plt.xlabel('預測標籤')\n",
    "    plt.ylabel('實際標籤')\n",
    "    plt.title('混淆矩陣 (BERT + BiLSTM)')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix_bert_bilstm.png')\n",
    "    plt.show()\n",
    "\n",
    "    # 繪製訓練/驗證曲線\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(1, len(train_losses)+1), train_losses, label='訓練損失')\n",
    "    plt.plot(range(1, len(val_losses)+1), val_losses, label='驗證損失')\n",
    "    plt.xlabel('輪次')\n",
    "    plt.ylabel('損失')\n",
    "    plt.title('訓練/驗證損失曲線')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(1, len(val_accuracies)+1), val_accuracies, label='驗證準確率', color='green')\n",
    "    plt.xlabel('輪次')\n",
    "    plt.ylabel('準確率')\n",
    "    plt.title('驗證準確率曲線')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('final_training_curves.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009d2a26",
   "metadata": {},
   "source": [
    "## 步驟10：最終訓練與視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efef6644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "階段一：測試 batch_size 和 learning_rate\n",
      "\n",
      "測試參數：batch_size=64, learning_rate=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:06<00:00,  3.45it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.7002, 訓練準確率: 0.1989\n",
      "驗證損失: 1.6162, 驗證準確率: 0.2738, F1: 0.1178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:14<00:00,  3.30it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.7029, 訓練準確率: 0.2041\n",
      "驗證損失: 1.6797, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:18<00:00,  3.24it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.7023, 訓練準確率: 0.2388\n",
      "驗證損失: 1.7097, 驗證準確率: 0.1577, F1: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:18<00:00,  3.25it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.6550, 訓練準確率: 0.2041\n",
      "驗證損失: 1.6146, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:23<00:00,  3.16it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:10<00:00,  5.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.6851, 訓練準確率: 0.2162\n",
      "驗證損失: 1.6758, 驗證準確率: 0.1559, F1: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:20<00:00,  3.21it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.7013, 訓練準確率: 0.2251\n",
      "驗證損失: 1.7262, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.22it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.6643, 訓練準確率: 0.2274\n",
      "驗證損失: 1.6091, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:21<00:00,  3.20it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.6099, 訓練準確率: 0.2169\n",
      "驗證損失: 1.6095, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:21<00:00,  3.20it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 9/15, 訓練損失: 1.6096, 訓練準確率: 0.2278\n",
      "驗證損失: 1.6094, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:20<00:00,  3.20it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 10/15, 訓練損失: 1.6095, 訓練準確率: 0.2585\n",
      "驗證損失: 1.6095, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:21<00:00,  3.20it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 11/15, 訓練損失: 1.6094, 訓練準確率: 0.2410\n",
      "驗證損失: 1.6095, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:20<00:00,  3.21it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 12/15, 訓練損失: 1.6095, 訓練準確率: 0.2572\n",
      "驗證損失: 1.6097, 驗證準確率: 0.2493, F1: 0.0995\n",
      "早停於輪次 12\n",
      "\n",
      "測試參數：batch_size=64, learning_rate=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:21<00:00,  3.20it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.6027, 訓練準確率: 0.2054\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:21<00:00,  3.20it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.6095, 訓練準確率: 0.2038\n",
      "驗證損失: 1.6104, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:21<00:00,  3.19it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.6095, 訓練準確率: 0.2498\n",
      "驗證損失: 1.6098, 驗證準確率: 0.1577, F1: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:18<00:00,  3.24it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.6095, 訓練準確率: 0.2432\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:16<00:00,  3.28it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.6095, 訓練準確率: 0.2368\n",
      "驗證損失: 1.6093, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:14<00:00,  3.32it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.6095, 訓練準確率: 0.2619\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:12<00:00,  3.34it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.6094, 訓練準確率: 0.2754\n",
      "驗證損失: 1.6096, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:13<00:00,  3.33it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.6094, 訓練準確率: 0.2163\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:12<00:00,  3.35it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 9/15, 訓練損失: 1.6094, 訓練準確率: 0.2775\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:12<00:00,  3.34it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 10/15, 訓練損失: 1.6094, 訓練準確率: 0.2775\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n",
      "早停於輪次 10\n",
      "\n",
      "測試參數：batch_size=64, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.23it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.5840, 訓練準確率: 0.2062\n",
      "驗證損失: 1.5756, 驗證準確率: 0.2059, F1: 0.1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.22it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.5800, 訓練準確率: 0.2078\n",
      "驗證損失: 1.5734, 驗證準確率: 0.2130, F1: 0.1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.23it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.5708, 訓練準確率: 0.2197\n",
      "驗證損失: 1.5710, 驗證準確率: 0.2104, F1: 0.1253\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.24it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.5638, 訓練準確率: 0.2308\n",
      "驗證損失: 1.5706, 驗證準確率: 0.2088, F1: 0.1352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:18<00:00,  3.24it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.5568, 訓練準確率: 0.2327\n",
      "驗證損失: 1.5700, 驗證準確率: 0.2125, F1: 0.1403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:18<00:00,  3.25it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.5522, 訓練準確率: 0.2351\n",
      "驗證損失: 1.5767, 驗證準確率: 0.2088, F1: 0.1327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:18<00:00,  3.24it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.5490, 訓練準確率: 0.2383\n",
      "驗證損失: 1.5749, 驗證準確率: 0.2127, F1: 0.1391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.24it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.5462, 訓練準確率: 0.2465\n",
      "驗證損失: 1.5745, 驗證準確率: 0.2146, F1: 0.1411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.23it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 9/15, 訓練損失: 1.5437, 訓練準確率: 0.2546\n",
      "驗證損失: 1.5760, 驗證準確率: 0.2114, F1: 0.1376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 644/644 [03:19<00:00,  3.23it/s]\n",
      "驗證: 100%|██████████| 60/60 [00:08<00:00,  7.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 10/15, 訓練損失: 1.5423, 訓練準確率: 0.2514\n",
      "驗證損失: 1.5763, 驗證準確率: 0.2120, F1: 0.1383\n",
      "早停於輪次 10\n",
      "\n",
      "測試參數：batch_size=128, learning_rate=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:10<00:00,  1.69it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:08<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.6981, 訓練準確率: 0.2010\n",
      "驗證損失: 1.6745, 驗證準確率: 0.1559, F1: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:10<00:00,  1.69it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.7028, 訓練準確率: 0.1829\n",
      "驗證損失: 1.7268, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:10<00:00,  1.69it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:08<00:00,  3.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.6491, 訓練準確率: 0.2188\n",
      "驗證損失: 1.6380, 驗證準確率: 0.1577, F1: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:08<00:00,  1.71it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:08<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.7057, 訓練準確率: 0.1760\n",
      "驗證損失: 1.6748, 驗證準確率: 0.1559, F1: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:09<00:00,  1.70it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.7007, 訓練準確率: 0.2180\n",
      "驗證損失: 1.7268, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:09<00:00,  1.70it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:08<00:00,  3.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.7060, 訓練準確率: 0.1929\n",
      "驗證損失: 1.6792, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:09<00:00,  1.70it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.7040, 訓練準確率: 0.2000\n",
      "驗證損失: 1.6748, 驗證準確率: 0.1559, F1: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:06<00:00,  1.73it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.7050, 訓練準確率: 0.1618\n",
      "驗證損失: 1.7330, 驗證準確率: 0.1630, F1: 0.0457\n",
      "早停於輪次 8\n",
      "\n",
      "測試參數：batch_size=128, learning_rate=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:09<00:00,  1.70it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:08<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.6013, 訓練準確率: 0.2164\n",
      "驗證損失: 1.6094, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:09<00:00,  1.70it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:08<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.6096, 訓練準確率: 0.2173\n",
      "驗證損失: 1.6097, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:04<00:00,  1.74it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.6095, 訓練準確率: 0.2522\n",
      "驗證損失: 1.6094, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:01<00:00,  1.77it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.6095, 訓練準確率: 0.2286\n",
      "驗證損失: 1.6093, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:00<00:00,  1.78it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.6095, 訓練準確率: 0.2592\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:00<00:00,  1.79it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.6095, 訓練準確率: 0.2385\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [02:59<00:00,  1.79it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.6095, 訓練準確率: 0.2724\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [02:58<00:00,  1.80it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.6094, 訓練準確率: 0.2761\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [02:57<00:00,  1.81it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 9/15, 訓練損失: 1.6094, 訓練準確率: 0.2775\n",
      "驗證損失: 1.6096, 驗證準確率: 0.2493, F1: 0.0995\n",
      "早停於輪次 9\n",
      "\n",
      "測試參數：batch_size=128, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:04<00:00,  1.74it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.5852, 訓練準確率: 0.2064\n",
      "驗證損失: 1.5753, 驗證準確率: 0.2059, F1: 0.1079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:08<00:00,  1.71it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:08<00:00,  3.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.5825, 訓練準確率: 0.2056\n",
      "驗證損失: 1.5767, 驗證準確率: 0.2104, F1: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:10<00:00,  1.69it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.5782, 訓練準確率: 0.2098\n",
      "驗證損失: 1.5727, 驗證準確率: 0.2043, F1: 0.1164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:05<00:00,  1.73it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.5698, 訓練準確率: 0.2100\n",
      "驗證損失: 1.5731, 驗證準確率: 0.2143, F1: 0.1332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:02<00:00,  1.76it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.5645, 訓練準確率: 0.2237\n",
      "驗證損失: 1.5739, 驗證準確率: 0.2151, F1: 0.1421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:01<00:00,  1.77it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.5589, 訓練準確率: 0.2290\n",
      "驗證損失: 1.5749, 驗證準確率: 0.2085, F1: 0.1330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:02<00:00,  1.77it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:07<00:00,  3.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.5551, 訓練準確率: 0.2344\n",
      "驗證損失: 1.5716, 驗證準確率: 0.2135, F1: 0.1392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:10<00:00,  1.69it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:09<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.5517, 訓練準確率: 0.2415\n",
      "驗證損失: 1.5723, 驗證準確率: 0.2117, F1: 0.1371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:22<00:00,  1.59it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:10<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 9/15, 訓練損失: 1.5498, 訓練準確率: 0.2371\n",
      "驗證損失: 1.5732, 驗證準確率: 0.2112, F1: 0.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:27<00:00,  1.55it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:09<00:00,  3.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 10/15, 訓練損失: 1.5485, 訓練準確率: 0.2424\n",
      "驗證損失: 1.5734, 驗證準確率: 0.2112, F1: 0.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:25<00:00,  1.57it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:10<00:00,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 11/15, 訓練損失: 1.5485, 訓練準確率: 0.2446\n",
      "驗證損失: 1.5734, 驗證準確率: 0.2112, F1: 0.1361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 322/322 [03:26<00:00,  1.56it/s]\n",
      "驗證: 100%|██████████| 30/30 [00:09<00:00,  3.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 12/15, 訓練損失: 1.5477, 訓練準確率: 0.2447\n",
      "驗證損失: 1.5735, 驗證準確率: 0.2109, F1: 0.1360\n",
      "早停於輪次 12\n",
      "\n",
      "測試參數：batch_size=256, learning_rate=0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [05:08<00:00,  1.92s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.6704, 訓練準確率: 0.2244\n",
      "驗證損失: 1.7324, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:59<00:00,  1.86s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.7037, 訓練準確率: 0.2328\n",
      "驗證損失: 1.7270, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [05:01<00:00,  1.87s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.7044, 訓練準確率: 0.1690\n",
      "驗證損失: 1.6736, 驗證準確率: 0.1559, F1: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:56<00:00,  1.84s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.7041, 訓練準確率: 0.1699\n",
      "驗證損失: 1.7324, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:54<00:00,  1.83s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.6419, 訓練準確率: 0.2018\n",
      "驗證損失: 1.6112, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:52<00:00,  1.82s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.6104, 訓練準確率: 0.1936\n",
      "驗證損失: 1.6100, 驗證準確率: 0.1577, F1: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:54<00:00,  1.83s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.6098, 訓練準確率: 0.2179\n",
      "驗證損失: 1.6088, 驗證準確率: 0.1559, F1: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:47<00:00,  1.79s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:08<00:00,  1.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.6096, 訓練準確率: 0.1880\n",
      "驗證損失: 1.6098, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:48<00:00,  1.79s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:09<00:00,  1.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 9/15, 訓練損失: 1.6095, 訓練準確率: 0.2234\n",
      "驗證損失: 1.6101, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:46<00:00,  1.78s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:08<00:00,  1.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 10/15, 訓練損失: 1.6095, 訓練準確率: 0.2230\n",
      "驗證損失: 1.6099, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:48<00:00,  1.79s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:08<00:00,  1.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 11/15, 訓練損失: 1.6095, 訓練準確率: 0.2690\n",
      "驗證損失: 1.6099, 驗證準確率: 0.2493, F1: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:45<00:00,  1.78s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:08<00:00,  1.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 12/15, 訓練損失: 1.6095, 訓練準確率: 0.2352\n",
      "驗證損失: 1.6097, 驗證準確率: 0.2493, F1: 0.0995\n",
      "早停於輪次 12\n",
      "\n",
      "測試參數：batch_size=256, learning_rate=0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:42<00:00,  1.75s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.6087, 訓練準確率: 0.1979\n",
      "驗證損失: 1.6106, 驗證準確率: 0.1577, F1: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:38<00:00,  1.73s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 2/15, 訓練損失: 1.6082, 訓練準確率: 0.2017\n",
      "驗證損失: 1.6101, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:40<00:00,  1.74s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 3/15, 訓練損失: 1.6095, 訓練準確率: 0.1942\n",
      "驗證損失: 1.6092, 驗證準確率: 0.1559, F1: 0.0420\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:37<00:00,  1.72s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 4/15, 訓練損失: 1.6095, 訓練準確率: 0.2026\n",
      "驗證損失: 1.6097, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:37<00:00,  1.72s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 5/15, 訓練損失: 1.6095, 訓練準確率: 0.1832\n",
      "驗證損失: 1.6092, 驗證準確率: 0.1577, F1: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:37<00:00,  1.72s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 6/15, 訓練損失: 1.6095, 訓練準確率: 0.1981\n",
      "驗證損失: 1.6093, 驗證準確率: 0.1577, F1: 0.0430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:37<00:00,  1.72s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 7/15, 訓練損失: 1.6095, 訓練準確率: 0.2219\n",
      "驗證損失: 1.6094, 驗證準確率: 0.2741, F1: 0.1179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:36<00:00,  1.72s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 8/15, 訓練損失: 1.6095, 訓練準確率: 0.1831\n",
      "驗證損失: 1.6095, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:38<00:00,  1.73s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 9/15, 訓練損失: 1.6094, 訓練準確率: 0.2156\n",
      "驗證損失: 1.6095, 驗證準確率: 0.1630, F1: 0.0457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:40<00:00,  1.74s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 10/15, 訓練損失: 1.6094, 訓練準確率: 0.2256\n",
      "驗證損失: 1.6095, 驗證準確率: 0.2741, F1: 0.1179\n",
      "早停於輪次 10\n",
      "\n",
      "測試參數：batch_size=256, learning_rate=0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練: 100%|██████████| 161/161 [04:39<00:00,  1.74s/it]\n",
      "驗證: 100%|██████████| 15/15 [00:07<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "輪次 1/15, 訓練損失: 1.5870, 訓練準確率: 0.2047\n",
      "驗證損失: 1.5756, 驗證準確率: 0.2104, F1: 0.1098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "訓練:  84%|████████▍ | 135/161 [03:57<00:45,  1.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mstaged_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 42\u001b[0m, in \u001b[0;36mstaged_search\u001b[1;34m()\u001b[0m\n\u001b[0;32m     40\u001b[0m counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m---> 42\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     val_loss, val_acc, val_f1, _, _ \u001b[38;5;241m=\u001b[39m evaluate(model, test_loader, criterion, device)\n\u001b[0;32m     44\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[1;32mIn[12], line 13\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, data_loader, criterion, optimizer, device)\u001b[0m\n\u001b[0;32m     11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids, attention_mask)\n\u001b[0;32m     12\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), CLIP_GRAD_NORM)\n\u001b[0;32m     15\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\skych\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\_tensor.py:648\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    638\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    640\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    641\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    646\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    647\u001b[0m     )\n\u001b[1;32m--> 648\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skych\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\autograd\\__init__.py:353\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    348\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    350\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    351\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    352\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 353\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\skych\\anaconda3\\envs\\DL\\lib\\site-packages\\torch\\autograd\\graph.py:824\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    822\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    823\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 824\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Variable\u001b[38;5;241m.\u001b[39m_execution_engine\u001b[38;5;241m.\u001b[39mrun_backward(  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    825\u001b[0m         t_outputs, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    826\u001b[0m     )  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "staged_search()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
